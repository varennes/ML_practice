{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import relevant libraries, datasets of interest, classifiers, and performance metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm, metrics\n",
    "digits = datasets.load_digits();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each digit is comprised of an 8x8 pixel image.\n",
    "We can reshape the image data to make a matrix in which each row represents an image, and the columns are the pixel values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1797 total images of digits, each with 64 pixels.\n",
      "x has dimensions (1797, 65)\n",
      "y has dimensions (1797, 1)\n"
     ]
    }
   ],
   "source": [
    "nDigits = digits.images.shape[0]\n",
    "x = digits.images.reshape( nDigits, 64)\n",
    "x = np.insert( x, 0, 1, axis=1)\n",
    "y = digits.target.reshape( nDigits, 1)\n",
    "\n",
    "print 'There are %i total images of digits, each with 64 pixels.' % nDigits\n",
    "print 'x has dimensions %s' %(x.shape,)\n",
    "print 'y has dimensions %s' %(y.shape,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform logistic regression on the features contained in the pixel values of the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit # the logistic function \n",
    "\n",
    "def CostFunction( theta, x, y, l):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    theta = parameters of logistic regression\n",
    "    x = features of our data\n",
    "    y = classifiers of our data\n",
    "    l = \"lambda,\" regularization parameter\n",
    "    OUTPUTS:\n",
    "    J = logistic regression cost function\n",
    "    '''\n",
    "    m = y.shape[0]\n",
    "    h = expit(x.dot(theta))\n",
    "    J =  np.log(h).dot(-y.T) - np.log( 1-h).dot( 1-y.T)\n",
    "    J += theta.T.dot(theta) * l * 0.5 \n",
    "    J = J / m;\n",
    "    return J\n",
    "\n",
    "def CostGradient( theta, x, y, l):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    theta = parameters of logistic regression\n",
    "    x = features of our data\n",
    "    y = classifiers of our data\n",
    "    l = \"lambda,\" regularization parameter\n",
    "    OUTPUTS:\n",
    "    gradJ = gradient of cost function\n",
    "    '''\n",
    "    m = y.shape[0];\n",
    "    h = expit(x.dot(theta));\n",
    "    gradJ = x.T.dot( expit(x.dot(theta)) - y.T)\n",
    "    gradJ[1:] += theta[1:]*(1.*l)\n",
    "    gradJ = gradJ*(1./m)\n",
    "    return gradJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to see if functions work without any errors\n",
    "initial_theta = np.zeros((x.shape[1],1))\n",
    "J = CostFunction( initial_theta, x, y, 0.0)\n",
    "gradJ = CostGradient( initial_theta, x, y, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_cg\n",
    "\n",
    "def ThetaOneVsAll( Nclass, x, y):\n",
    "    '''\n",
    "    Calculate the optimal parameter values of theta for each class\n",
    "    INPUT:\n",
    "    Nclass = number of classes\n",
    "    OUTPUT\n",
    "    thetaMatrix = Matrix of optimal parameters, each row corresponds to a class\n",
    "    '''\n",
    "    thetaMatrix = np.zeros((Nclass, len(x[0])))\n",
    "    thetai = np.zeros((len(x[0]),1))\n",
    "    thetai = thetai.reshape(len(thetai),)\n",
    "    \n",
    "    ytemp = y.reshape( len(y),)\n",
    "    # one-vs-all classification\n",
    "    # perform logistic regression for each class, training each independently\n",
    "    for i in xrange(Nclass):\n",
    "        yClass = np.array([ 1 if yi == 1 else 0 for yi in ytemp])\n",
    "        print 'Optimizing for digit %d '%i\n",
    "        \n",
    "        out = fmin_cg( CostFunction, x0=thetai, fprime=CostGradient, \\\n",
    "                    args=(x,yClass,0.0), maxiter=50, disp=False)\n",
    "\n",
    "        thetaMatrix[i,:] = out[0]\n",
    "\n",
    "    return thetaMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 65) <type 'numpy.ndarray'>\n",
      "(1797, 1) <type 'numpy.ndarray'>\n",
      "Optimizing for digit 0 \n",
      "Optimizing for digit 1 \n",
      "Optimizing for digit 2 \n",
      "Optimizing for digit 3 \n",
      "Optimizing for digit 4 \n",
      "Optimizing for digit 5 \n",
      "Optimizing for digit 6 \n",
      "Optimizing for digit 7 \n",
      "Optimizing for digit 8 \n",
      "Optimizing for digit 9 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "print x.shape, type(x)\n",
    "print y.shape, type(y)\n",
    "thetaMatrix = ThetaOneVsAll( 10, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The prediction for the i'th row is found to be the index at which Theta*X[i] is maximized\n",
    "def PredictOveVsAll( thetaMatrix, x):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    thetaMatrix = Matrix of optimal parameters, each row corresponds to a class\n",
    "    OUTPUT:\n",
    "    pred = predicted class for each corresponding to each row in X\n",
    "    '''\n",
    "    pred = np.argmax( expit(x.dot(thetaMatrix.T)), axis=1)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredict = PredictOveVsAll( thetaMatrix, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 9.9%\n"
     ]
    }
   ],
   "source": [
    "n_correct, n_total = 0., 0.\n",
    "incorrect_indices = []\n",
    "for irow in xrange(x.shape[0]):\n",
    "    n_total += 1\n",
    "    if yPredict[irow] == y[irow][0]: \n",
    "        n_correct += 1\n",
    "    else: incorrect_indices.append(irow)\n",
    "print \"Training set accuracy: %0.1f%%\"%(100*(n_correct/n_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
